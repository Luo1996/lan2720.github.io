<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>tensorflow的legacy_seq2seq | Lan&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="tensorflow要重新给出一套seq2seq的接口，把之前的seq2seq搬到了legacy_seq2seq下，今天读的就是来自这里的代码。目前很多代码还是使用了老的seq2seq接口，因此仍有熟悉的必要。
_extract_argmax_and_embed1234567891011121314151617181920212223242526def _extract_argmax_and_em">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow的legacy_seq2seq">
<meta property="og:url" content="http://lan2720.github.io/2017/03/10/tensorflow的legacy-seq2seq/index.html">
<meta property="og:site_name" content="Lan's Blog">
<meta property="og:description" content="tensorflow要重新给出一套seq2seq的接口，把之前的seq2seq搬到了legacy_seq2seq下，今天读的就是来自这里的代码。目前很多代码还是使用了老的seq2seq接口，因此仍有熟悉的必要。
_extract_argmax_and_embed1234567891011121314151617181920212223242526def _extract_argmax_and_em">
<meta property="og:image" content="http://ww1.sinaimg.cn/large/901f9a6fly1fdggohp275j20hp062ta6">
<meta property="og:updated_time" content="2017-03-10T15:13:34.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="tensorflow的legacy_seq2seq">
<meta name="twitter:description" content="tensorflow要重新给出一套seq2seq的接口，把之前的seq2seq搬到了legacy_seq2seq下，今天读的就是来自这里的代码。目前很多代码还是使用了老的seq2seq接口，因此仍有熟悉的必要。
_extract_argmax_and_embed1234567891011121314151617181920212223242526def _extract_argmax_and_em">
<meta name="twitter:image" content="http://ww1.sinaimg.cn/large/901f9a6fly1fdggohp275j20hp062ta6">
  
    <link rel="alternate" href="/atom.xml" title="Lan&#39;s Blog" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
  

</head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Lan&#39;s Blog</a>
      </h1>
      
        <h2 id="subtitle-wrap">
          <a href="/" id="subtitle">the stack of it nerds</a>
        </h2>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="搜索"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" results="0" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://lan2720.github.io"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-tensorflow的legacy-seq2seq" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    <a href="/2017/03/10/tensorflow的legacy-seq2seq/" class="article-date">
  <time datetime="2017-03-10T14:50:19.000Z" itemprop="datePublished">2017-03-10</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      tensorflow的legacy_seq2seq
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>tensorflow要重新给出一套seq2seq的接口，把之前的seq2seq搬到了legacy_seq2seq下，今天读的就是来自<a href="https://github.com/tensorflow/tensorflow/blob/r1.0/tensorflow/contrib/legacy_seq2seq/python/ops/seq2seq.py" target="_blank" rel="external">这里</a>的代码。目前很多代码还是使用了老的seq2seq接口，因此仍有熟悉的必要。</p>
<h3 id="extract-argmax-and-embed"><a href="#extract-argmax-and-embed" class="headerlink" title="_extract_argmax_and_embed"></a>_extract_argmax_and_embed</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">_extract_argmax_and_embed</span><span class="params">(embedding,</span></span></div><div class="line">                              output_projection=None,</div><div class="line">                              update_embedding=True):</div><div class="line">  <span class="string">"""Get a loop_function that extracts the previous symbol and embeds it.</span></div><div class="line">  Args:</div><div class="line">    embedding: embedding tensor for symbols.</div><div class="line">    output_projection: None or a pair (W, B). If provided, each fed previous</div><div class="line">      output will first be multiplied by W and added B.</div><div class="line">    update_embedding: Boolean; if False, the gradients will not propagate</div><div class="line">      through the embeddings.</div><div class="line">  Returns:</div><div class="line">    A loop function.</div><div class="line">  """</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">def</span> <span class="title">loop_function</span><span class="params">(prev, _)</span>:</span></div><div class="line">    <span class="keyword">if</span> output_projection <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      prev = nn_ops.xw_plus_b(prev, output_projection[<span class="number">0</span>], output_projection[<span class="number">1</span>])</div><div class="line">    prev_symbol = math_ops.argmax(prev, <span class="number">1</span>)</div><div class="line">    <span class="comment"># Note that gradients will not propagate through the second parameter of</span></div><div class="line">    <span class="comment"># embedding_lookup.</span></div><div class="line">    emb_prev = embedding_ops.embedding_lookup(embedding, prev_symbol)</div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> update_embedding:</div><div class="line">      emb_prev = array_ops.stop_gradient(emb_prev)</div><div class="line">    <span class="keyword">return</span> emb_prev</div><div class="line"></div><div class="line">  <span class="keyword">return</span> loop_function</div></pre></td></tr></table></figure>
<h3 id="rnn-decoder"><a href="#rnn-decoder" class="headerlink" title="rnn_decoder"></a>rnn_decoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">rnn_decoder</span><span class="params">(decoder_inputs,</span></span></div><div class="line">                initial_state,</div><div class="line">                cell,</div><div class="line">                loop_function=None,</div><div class="line">                scope=None):</div><div class="line">  <span class="string">"""RNN decoder for the sequence-to-sequence model.</span></div><div class="line">  Args:</div><div class="line">    decoder_inputs: A list of 2D Tensors [batch_size x input_size].</div><div class="line">    initial_state: 2D Tensor with shape [batch_size x cell.state_size].</div><div class="line">    cell: core_rnn_cell.RNNCell defining the cell function and size.</div><div class="line">    loop_function: If not None, this function will be applied to the i-th output</div><div class="line">      in order to generate the i+1-st input, and decoder_inputs will be ignored,</div><div class="line">      except for the first element ("GO" symbol). This can be used for decoding,</div><div class="line">      but also for training to emulate http://arxiv.org/abs/1506.03099.</div><div class="line">      Signature -- loop_function(prev, i) = next</div><div class="line">        * prev is a 2D Tensor of shape [batch_size x output_size],</div><div class="line">        * i is an integer, the step number (when advanced control is needed),</div><div class="line">        * next is a 2D Tensor of shape [batch_size x input_size].</div><div class="line">    scope: VariableScope for the created subgraph; defaults to "rnn_decoder".</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, state), where:</div><div class="line">      outputs: A list of the same length as decoder_inputs of 2D Tensors with</div><div class="line">        shape [batch_size x output_size] containing generated outputs.</div><div class="line">      state: The state of each cell at the final time-step.</div><div class="line">        It is a 2D Tensor of shape [batch_size x cell.state_size].</div><div class="line">        (Note that in some cases, like basic RNN cell or GRU cell, outputs and</div><div class="line">         states can be the same. They are different for LSTM cells though.)</div><div class="line">  """</div><div class="line">  <span class="keyword">with</span> variable_scope.variable_scope(scope <span class="keyword">or</span> <span class="string">"rnn_decoder"</span>):</div><div class="line">    state = initial_state</div><div class="line">    outputs = []</div><div class="line">    prev = <span class="keyword">None</span></div><div class="line">    <span class="keyword">for</span> i, inp <span class="keyword">in</span> enumerate(decoder_inputs):</div><div class="line">      <span class="keyword">if</span> loop_function <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span> <span class="keyword">and</span> prev <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        <span class="keyword">with</span> variable_scope.variable_scope(<span class="string">"loop_function"</span>, reuse=<span class="keyword">True</span>):</div><div class="line">          inp = loop_function(prev, i)</div><div class="line">      <span class="keyword">if</span> i &gt; <span class="number">0</span>:</div><div class="line">        variable_scope.get_variable_scope().reuse_variables()</div><div class="line">      output, state = cell(inp, state)</div><div class="line">      outputs.append(output)</div><div class="line">      <span class="keyword">if</span> loop_function <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        prev = output</div><div class="line">  <span class="keyword">return</span> outputs, state</div></pre></td></tr></table></figure>
<p><code>decoder_inputs</code>：是a list，其中的每一个元素表示的是<code>t_i</code>时刻的输入，每一时刻的输入又会有batch_size个，每一个输入（通差是表示一个word或token）又是input_size维度的。<br><code>loop_function</code>: 如果loop_function有设置的话，decoder input中第一个”GO”会输入，但之后时刻的input就会被忽略，取代的是<code>input_ti+1 = loop_function(output_ti)</code><br>这里定义的loop_function，有2个参数，（prev,i），输出为next</p>
<p>输出：<br><code>outputs</code>：既然是每一时刻的input都会对应得到一个output，自然outputs的shape和decoder_inputs是一样，是a list，每个元素的shape=[batch_size, input_size]（但是这里为了区别，认为是output_size）<br><code>state</code>：最后一个时刻t的cell state，shape=[batch_size, cell.state_size]</p>
<h3 id="basic-rnn-seq2seq"><a href="#basic-rnn-seq2seq" class="headerlink" title="basic_rnn_seq2seq"></a>basic_rnn_seq2seq</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">basic_rnn_seq2seq</span><span class="params">(encoder_inputs,</span></span></div><div class="line">                      decoder_inputs,</div><div class="line">                      cell,</div><div class="line">                      dtype=dtypes.float32,</div><div class="line">                      scope=None):</div><div class="line">  <span class="string">"""Basic RNN sequence-to-sequence model.</span></div><div class="line">  This model first runs an RNN to encode encoder_inputs into a state vector,</div><div class="line">  then runs decoder, initialized with the last encoder state, on decoder_inputs.</div><div class="line">  Encoder and decoder use the same RNN cell type, but don't share parameters.</div><div class="line">  Args:</div><div class="line">    encoder_inputs: A list of 2D Tensors [batch_size x input_size].</div><div class="line">    decoder_inputs: A list of 2D Tensors [batch_size x input_size].</div><div class="line">    cell: core_rnn_cell.RNNCell defining the cell function and size.</div><div class="line">    dtype: The dtype of the initial state of the RNN cell (default: tf.float32).</div><div class="line">    scope: VariableScope for the created subgraph; default: "basic_rnn_seq2seq".</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, state), where:</div><div class="line">      outputs: A list of the same length as decoder_inputs of 2D Tensors with</div><div class="line">        shape [batch_size x output_size] containing the generated outputs.</div><div class="line">      state: The state of each decoder cell in the final time-step.</div><div class="line">        It is a 2D Tensor of shape [batch_size x cell.state_size].</div><div class="line">  """</div><div class="line">  <span class="keyword">with</span> variable_scope.variable_scope(scope <span class="keyword">or</span> <span class="string">"basic_rnn_seq2seq"</span>):</div><div class="line">    enc_cell = copy.deepcopy(cell)</div><div class="line">    _, enc_state = core_rnn.static_rnn(enc_cell, encoder_inputs, dtype=dtype)</div><div class="line">    <span class="keyword">return</span> rnn_decoder(decoder_inputs, enc_state, cell)</div></pre></td></tr></table></figure>
<p><code>encoder_inputs</code>：a list，每个元素是<code>时刻t</code>的输入，每一时刻又存在batch_size个输入（word or token），并且每个token用input_size来表示（embedding）。因此，是a list of [batch_size, input_size]<br><code>decoder_inputs</code>：同上，但是这两个<code>list的长度</code>可能不同，前者根据encoder_max_length指定，decoder根据decoder_max_length指定。<br>输出：<br><code>outputs</code>：shape和<code>decoder_inputs</code>相同，差别在于这里用output_size和input_size区别【why<br><code>state</code>：还是最后一个时刻的cell state，[batch_size, cell.state_size]</p>
<p>注意到这里用到<code>深拷贝</code>:</p>
<blockquote>
<p>深拷贝是在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。也就是说（ 新瓶装新酒 ）。</p>
</blockquote>
<p>encode阶段使用的是<code>core_rnn.static_rnn()</code>不知道这个函数和别的rnn有什么不同？</p>
<p>decode阶段，很基本，直接使用了上面提到的<code>rnn_decoder</code>来生成最后的outputs和state，返回。</p>
<h3 id="static-rnn"><a href="#static-rnn" class="headerlink" title="static_rnn"></a>static_rnn</h3><p>代码<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/rnn/python/ops/core_rnn.py#L41" target="_blank" rel="external">在这</a>，比较繁琐，就不详细解读了。</p>
<h3 id="embedding-rnn-decoder"><a href="#embedding-rnn-decoder" class="headerlink" title="embedding_rnn_decoder"></a>embedding_rnn_decoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_rnn_decoder</span><span class="params">(decoder_inputs,</span></span></div><div class="line">                          initial_state,</div><div class="line">                          cell,</div><div class="line">                          num_symbols,</div><div class="line">                          embedding_size,</div><div class="line">                          output_projection=None,</div><div class="line">                          feed_previous=False,</div><div class="line">                          update_embedding_for_previous=True,</div><div class="line">                          scope=None):</div><div class="line">  <span class="string">"""RNN decoder with embedding and a pure-decoding option.</span></div><div class="line">  Args:</div><div class="line">    decoder_inputs: A list of 1D batch-sized int32 Tensors (decoder inputs).</div><div class="line">    initial_state: 2D Tensor [batch_size x cell.state_size].</div><div class="line">    cell: core_rnn_cell.RNNCell defining the cell function.</div><div class="line">    num_symbols: Integer, how many symbols come into the embedding.</div><div class="line">    embedding_size: Integer, the length of the embedding vector for each symbol.</div><div class="line">    output_projection: None or a pair (W, B) of output projection weights and</div><div class="line">      biases; W has shape [output_size x num_symbols] and B has</div><div class="line">      shape [num_symbols]; if provided and feed_previous=True, each fed</div><div class="line">      previous output will first be multiplied by W and added B.</div><div class="line">    feed_previous: Boolean; if True, only the first of decoder_inputs will be</div><div class="line">      used (the "GO" symbol), and all other decoder inputs will be generated by:</div><div class="line">        next = embedding_lookup(embedding, argmax(previous_output)),</div><div class="line">      In effect, this implements a greedy decoder. It can also be used</div><div class="line">      during training to emulate http://arxiv.org/abs/1506.03099.</div><div class="line">      If False, decoder_inputs are used as given (the standard decoder case).</div><div class="line">    update_embedding_for_previous: Boolean; if False and feed_previous=True,</div><div class="line">      only the embedding for the first symbol of decoder_inputs (the "GO"</div><div class="line">      symbol) will be updated by back propagation. Embeddings for the symbols</div><div class="line">      generated from the decoder itself remain unchanged. This parameter has</div><div class="line">      no effect if feed_previous=False.</div><div class="line">    scope: VariableScope for the created subgraph; defaults to</div><div class="line">      "embedding_rnn_decoder".</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, state), where:</div><div class="line">      outputs: A list of the same length as decoder_inputs of 2D Tensors. The</div><div class="line">        output is of shape [batch_size x cell.output_size] when</div><div class="line">        output_projection is not None (and represents the dense representation</div><div class="line">        of predicted tokens). It is of shape [batch_size x num_decoder_symbols]</div><div class="line">        when output_projection is None.</div><div class="line">      state: The state of each decoder cell in each time-step. This is a list</div><div class="line">        with length len(decoder_inputs) -- one item for each time-step.</div><div class="line">        It is a 2D Tensor of shape [batch_size x cell.state_size].</div><div class="line">  Raises:</div><div class="line">    ValueError: When output_projection has the wrong shape.</div><div class="line">  """</div><div class="line">  <span class="keyword">with</span> variable_scope.variable_scope(scope <span class="keyword">or</span> <span class="string">"embedding_rnn_decoder"</span>) <span class="keyword">as</span> scope:</div><div class="line">    <span class="keyword">if</span> output_projection <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">      dtype = scope.dtype</div><div class="line">      proj_weights = ops.convert_to_tensor(output_projection[<span class="number">0</span>], dtype=dtype)</div><div class="line">      proj_weights.get_shape().assert_is_compatible_with([<span class="keyword">None</span>, num_symbols])</div><div class="line">      proj_biases = ops.convert_to_tensor(output_projection[<span class="number">1</span>], dtype=dtype)</div><div class="line">      proj_biases.get_shape().assert_is_compatible_with([num_symbols])</div><div class="line"></div><div class="line">    embedding = variable_scope.get_variable(<span class="string">"embedding"</span>,</div><div class="line">                                            [num_symbols, embedding_size])</div><div class="line">    loop_function = _extract_argmax_and_embed(</div><div class="line">        embedding, output_projection,</div><div class="line">        update_embedding_for_previous) <span class="keyword">if</span> feed_previous <span class="keyword">else</span> <span class="keyword">None</span></div><div class="line">    emb_inp = (embedding_ops.embedding_lookup(embedding, i)</div><div class="line">               <span class="keyword">for</span> i <span class="keyword">in</span> decoder_inputs)</div><div class="line">    <span class="keyword">return</span> rnn_decoder(</div><div class="line">        emb_inp, initial_state, cell, loop_function=loop_function)</div></pre></td></tr></table></figure>
<p>刚才讲了一个basic的decoder叫<code>rnn_decoder</code>：rnn_decoder(decoder_inputs,initial_state,cell,loop_function=None,scope=None)，现在来一个稍微高级一点的。<br>对比一下发现这个decoder没有loop_function，多出来了<code>num_symbols</code>，<code>embedding_size</code>，<code>output_projection=None</code>，<code>feed_previous=False</code>，<code>update_embedding_for_previous=True</code>。这些都是什么呢？</p>
<p>参数：<br><code>decoder_inputs</code>：既然这个标榜了embedding，那么input肯定和rnn_decoder有些不同。这里input变为1维，[batch_size, ]也就是说，输入不需要自己做embedding了，直接输入tokens在vocab中对应的idx（即ids）即可，内部会自动帮我们进行id到embedding的转化。<br><code>num_symbols</code>：就是vocab_size<br><code>embedding_size</code>：每个token需要embedding成的维数，比如100<br><code>output_projection</code>：(W, b)就是将输出做一个映射。为什么要映射，因为此时input相当于a list of [batch_size, 1]，内部帮我们做一个embedding，得到embedded_input=[batch_size, embedding_size ]，经过cell之后，得到[batch_size, output_size]（这个过程就是之前的rnn_decoder做的事情）。这样之后，如果我们设置了feed_previous=True，也就是需要将前一时刻的output作为下一时刻的input，那么前一时刻的output中要从vocab_size中选出一个分数最高的token来，即argmax(previous_output)。过程如下图描述的那样：<br><img src="http://ww1.sinaimg.cn/large/901f9a6fly1fdggohp275j20hp062ta6" alt=""><br>但是，现在的output维度是output_size，并不能知道每个vocab的得分情况。因此要从output_size映射到vocab_size（这里的num_symbols）。<br>我们知道，x(某一时刻的output)的shape=[batch_size, output_size]，映射的公式是xw+b，那么w的shape=[output_zize, num_symbols]</p>
<p><code>update_embedding_for_previous</code>：如果前一时刻的output不作为当前的input的话(feed_previous=False)，这个参数没影响（）；否则，该参数默认是True，但如果设置成false，则表示不对前一个embedding进行更新，那么bp的时候只会更新”GO”的embedding，其他token（decoder生成的）embedding不变。</p>
<p>输出：<br><code>outputs</code>：如果output_projection=None的话，也就是不进行映射(直接输出的是num_symbols的个数)，那么a list of [batch_size, num_symbols]；如果不为None，说明outputs要进行映射，则outputs是a list of [batch_size, num_symbols]<br><code>state</code>同上</p>
<h3 id="embedding-rnn-seq2seq"><a href="#embedding-rnn-seq2seq" class="headerlink" title="embedding_rnn_seq2seq"></a>embedding_rnn_seq2seq</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div></pre></td><td class="code"><pre><div class="line">def embedding_rnn_seq2seq(encoder_inputs,</div><div class="line">                          decoder_inputs,</div><div class="line">                          cell,</div><div class="line">                          num_encoder_symbols,</div><div class="line">                          num_decoder_symbols,</div><div class="line">                          embedding_size,</div><div class="line">                          output_projection=None,</div><div class="line">                          feed_previous=False,</div><div class="line">                          dtype=None,</div><div class="line">                          scope=None):</div><div class="line">  &quot;&quot;&quot;Embedding RNN sequence-to-sequence model.</div><div class="line">  This model first embeds encoder_inputs by a newly created embedding (of shape</div><div class="line">  [num_encoder_symbols x input_size]). Then it runs an RNN to encode</div><div class="line">  embedded encoder_inputs into a state vector. Next, it embeds decoder_inputs</div><div class="line">  by another newly created embedding (of shape [num_decoder_symbols x</div><div class="line">  input_size]). Then it runs RNN decoder, initialized with the last</div><div class="line">  encoder state, on embedded decoder_inputs.</div><div class="line">  Args:</div><div class="line">    encoder_inputs: A list of 1D int32 Tensors of shape [batch_size].</div><div class="line">    decoder_inputs: A list of 1D int32 Tensors of shape [batch_size].</div><div class="line">    cell: core_rnn_cell.RNNCell defining the cell function and size.</div><div class="line">    num_encoder_symbols: Integer; number of symbols on the encoder side.</div><div class="line">    num_decoder_symbols: Integer; number of symbols on the decoder side.</div><div class="line">    embedding_size: Integer, the length of the embedding vector for each symbol.</div><div class="line">    output_projection: None or a pair (W, B) of output projection weights and</div><div class="line">      biases; W has shape [output_size x num_decoder_symbols] and B has</div><div class="line">      shape [num_decoder_symbols]; if provided and feed_previous=True, each</div><div class="line">      fed previous output will first be multiplied by W and added B.</div><div class="line">    feed_previous: Boolean or scalar Boolean Tensor; if True, only the first</div><div class="line">      of decoder_inputs will be used (the &quot;GO&quot; symbol), and all other decoder</div><div class="line">      inputs will be taken from previous outputs (as in embedding_rnn_decoder).</div><div class="line">      If False, decoder_inputs are used as given (the standard decoder case).</div><div class="line">    dtype: The dtype of the initial state for both the encoder and encoder</div><div class="line">      rnn cells (default: tf.float32).</div><div class="line">    scope: VariableScope for the created subgraph; defaults to</div><div class="line">      &quot;embedding_rnn_seq2seq&quot;</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, state), where:</div><div class="line">      outputs: A list of the same length as decoder_inputs of 2D Tensors. The</div><div class="line">        output is of shape [batch_size x cell.output_size] when</div><div class="line">        output_projection is not None (and represents the dense representation</div><div class="line">        of predicted tokens). It is of shape [batch_size x num_decoder_symbols]</div><div class="line">        when output_projection is None.</div><div class="line">      state: The state of each decoder cell in each time-step. This is a list</div><div class="line">        with length len(decoder_inputs) -- one item for each time-step.</div><div class="line">        It is a 2D Tensor of shape [batch_size x cell.state_size].</div><div class="line">  &quot;&quot;&quot;</div></pre></td></tr></table></figure>
<p>既然有了embedding_rnn_decoder，那么对应的就有embedding_rnn_seq2seq。之前讲过basic_rnn_seq2seq(encoder_inputs, decoder_inputs, cell, dtype=dtypes.float32, scope=None)<br><code>inputs</code>：还是像之前说的，既然embedding是内部帮我们完成，则inputs shape= a list of [batch_size]，每个位置都只是一个token id。内部使用一个embedding wrapper，做lookup，生成a list of [batch_size, embedding_size]<br>对比之下，多了几个参数：<br><code>num_encoder_symbols</code>：通俗的说其实就是encoder端的vocab_size。enc和dec两端词汇量不同主要在于不同语言的translate task中，如果单纯是中文到中文的生成，不存在两端词汇量的不同。<br><code>num_decoder_symbols</code>：同上<br><code>embedding_size</code>：每个vocab需要用多少维的vector表示<br><code>output_projection=None</code>：<br><code>feed_previous=False</code>：如果feed_previous只是简单的一个True or False，则直接返回embedding_rnn_decoder的结果。重点是feed_previous还能传入一个boolean tensor（暂时无此需求）</p>
<h3 id="attention-decoder"><a href="#attention-decoder" class="headerlink" title="attention_decoder"></a>attention_decoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">attention_decoder</span><span class="params">(decoder_inputs,</span></span></div><div class="line">                      initial_state,</div><div class="line">                      attention_states,</div><div class="line">                      cell,</div><div class="line">                      output_size=None,</div><div class="line">                      num_heads=<span class="number">1</span>,</div><div class="line">                      loop_function=None,</div><div class="line">                      dtype=None,</div><div class="line">                      scope=None,</div><div class="line">                      initial_state_attention=False):</div><div class="line">  <span class="string">"""RNN decoder with attention for the sequence-to-sequence model.</span></div><div class="line">  In this context "attention" means that, during decoding, the RNN can look up</div><div class="line">  information in the additional tensor attention_states, and it does this by</div><div class="line">  focusing on a few entries from the tensor. This model has proven to yield</div><div class="line">  especially good results in a number of sequence-to-sequence tasks. This</div><div class="line">  implementation is based on http://arxiv.org/abs/1412.7449 (see below for</div><div class="line">  details). It is recommended for complex sequence-to-sequence tasks.</div><div class="line">  Args:</div><div class="line">    decoder_inputs: A list of 2D Tensors [batch_size x input_size].</div><div class="line">    initial_state: 2D Tensor [batch_size x cell.state_size].</div><div class="line">    attention_states: 3D Tensor [batch_size x attn_length x attn_size].</div><div class="line">    cell: core_rnn_cell.RNNCell defining the cell function and size.</div><div class="line">    output_size: Size of the output vectors; if None, we use cell.output_size.</div><div class="line">    num_heads: Number of attention heads that read from attention_states.</div><div class="line">    loop_function: If not None, this function will be applied to i-th output</div><div class="line">      in order to generate i+1-th input, and decoder_inputs will be ignored,</div><div class="line">      except for the first element ("GO" symbol). This can be used for decoding,</div><div class="line">      but also for training to emulate http://arxiv.org/abs/1506.03099.</div><div class="line">      Signature -- loop_function(prev, i) = next</div><div class="line">        * prev is a 2D Tensor of shape [batch_size x output_size],</div><div class="line">        * i is an integer, the step number (when advanced control is needed),</div><div class="line">        * next is a 2D Tensor of shape [batch_size x input_size].</div><div class="line">    dtype: The dtype to use for the RNN initial state (default: tf.float32).</div><div class="line">    scope: VariableScope for the created subgraph; default: "attention_decoder".</div><div class="line">    initial_state_attention: If False (default), initial attentions are zero.</div><div class="line">      If True, initialize the attentions from the initial state and attention</div><div class="line">      states -- useful when we wish to resume decoding from a previously</div><div class="line">      stored decoder state and attention states.</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, state), where:</div><div class="line">      outputs: A list of the same length as decoder_inputs of 2D Tensors of</div><div class="line">        shape [batch_size x output_size]. These represent the generated outputs.</div><div class="line">        Output i is computed from input i (which is either the i-th element</div><div class="line">        of decoder_inputs or loop_function(output &#123;i-1&#125;, i)) as follows.</div><div class="line">        First, we run the cell on a combination of the input and previous</div><div class="line">        attention masks:</div><div class="line">          cell_output, new_state = cell(linear(input, prev_attn), prev_state).</div><div class="line">        Then, we calculate new attention masks:</div><div class="line">          new_attn = softmax(V^T * tanh(W * attention_states + U * new_state))</div><div class="line">        and then we calculate the output:</div><div class="line">          output = linear(cell_output, new_attn).</div><div class="line">      state: The state of each decoder cell the final time-step.</div><div class="line">        It is a 2D Tensor of shape [batch_size x cell.state_size].</div><div class="line">  Raises:</div><div class="line">    ValueError: when num_heads is not positive, there are no inputs, shapes</div><div class="line">      of attention_states are not set, or input size cannot be inferred</div><div class="line">      from the input.</div><div class="line">  """</div></pre></td></tr></table></figure>
<p>刚才讲完了embedding_rnn_decoder，则再来看看attention_decoder。<br>和基本的rnn_decoder相比（rnn_decoder(decoder_inputs, initial_state, cell, loop_function=None, scope=None)）<br>多了几个参数：<br><code>attention_states</code>：attention_states作为addition info出现，<br><code>output_size=None</code>：如果是None的话默认为cell.output_size<br><code>num_heads=1</code> :应该pay attention的点的个数，比如要focus到attention_states的几个点，默认为只关注1个点<br><code>initial_state_attention=False</code>：如果是True的话，attention由state和attention_states进行初始化，如果False，则attention初始化为0</p>
<h3 id="embedding-attention-decoder"><a href="#embedding-attention-decoder" class="headerlink" title="embedding_attention_decoder"></a>embedding_attention_decoder</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_attention_decoder</span><span class="params">(decoder_inputs,</span></span></div><div class="line">                                initial_state,</div><div class="line">                                attention_states,</div><div class="line">                                cell,</div><div class="line">                                num_symbols,</div><div class="line">                                embedding_size,</div><div class="line">                                num_heads=<span class="number">1</span>,</div><div class="line">                                output_size=None,</div><div class="line">                                output_projection=None,</div><div class="line">                                feed_previous=False,</div><div class="line">                                update_embedding_for_previous=True,</div><div class="line">                                dtype=None,</div><div class="line">                                scope=None,</div><div class="line">                                initial_state_attention=False):</div><div class="line">  <span class="string">"""RNN decoder with embedding and attention and a pure-decoding option.</span></div><div class="line">  Args:</div><div class="line">    decoder_inputs: A list of 1D batch-sized int32 Tensors (decoder inputs).</div><div class="line">    initial_state: 2D Tensor [batch_size x cell.state_size].</div><div class="line">    attention_states: 3D Tensor [batch_size x attn_length x attn_size].</div><div class="line">    cell: core_rnn_cell.RNNCell defining the cell function.</div><div class="line">    num_symbols: Integer, how many symbols come into the embedding.</div><div class="line">    embedding_size: Integer, the length of the embedding vector for each symbol.</div><div class="line">    num_heads: Number of attention heads that read from attention_states.</div><div class="line">    output_size: Size of the output vectors; if None, use output_size.</div><div class="line">    output_projection: None or a pair (W, B) of output projection weights and</div><div class="line">      biases; W has shape [output_size x num_symbols] and B has shape</div><div class="line">      [num_symbols]; if provided and feed_previous=True, each fed previous</div><div class="line">      output will first be multiplied by W and added B.</div><div class="line">    feed_previous: Boolean; if True, only the first of decoder_inputs will be</div><div class="line">      used (the "GO" symbol), and all other decoder inputs will be generated by:</div><div class="line">        next = embedding_lookup(embedding, argmax(previous_output)),</div><div class="line">      In effect, this implements a greedy decoder. It can also be used</div><div class="line">      during training to emulate http://arxiv.org/abs/1506.03099.</div><div class="line">      If False, decoder_inputs are used as given (the standard decoder case).</div><div class="line">    update_embedding_for_previous: Boolean; if False and feed_previous=True,</div><div class="line">      only the embedding for the first symbol of decoder_inputs (the "GO"</div><div class="line">      symbol) will be updated by back propagation. Embeddings for the symbols</div><div class="line">      generated from the decoder itself remain unchanged. This parameter has</div><div class="line">      no effect if feed_previous=False.</div><div class="line">    dtype: The dtype to use for the RNN initial states (default: tf.float32).</div><div class="line">    scope: VariableScope for the created subgraph; defaults to</div><div class="line">      "embedding_attention_decoder".</div><div class="line">    initial_state_attention: If False (default), initial attentions are zero.</div><div class="line">      If True, initialize the attentions from the initial state and attention</div><div class="line">      states -- useful when we wish to resume decoding from a previously</div><div class="line">      stored decoder state and attention states.</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, state), where:</div><div class="line">      outputs: A list of the same length as decoder_inputs of 2D Tensors with</div><div class="line">        shape [batch_size x output_size] containing the generated outputs.</div><div class="line">      state: The state of each decoder cell at the final time-step.</div><div class="line">        It is a 2D Tensor of shape [batch_size x cell.state_size].</div><div class="line">  Raises:</div><div class="line">    ValueError: When output_projection has the wrong shape.</div><div class="line">  """</div></pre></td></tr></table></figure>
<p>其实是前面讲的embedding_decoder和attention_decoder的结合版。</p>
<h3 id="embedding-attention-seq2seq"><a href="#embedding-attention-seq2seq" class="headerlink" title="embedding_attention_seq2seq"></a>embedding_attention_seq2seq</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">embedding_attention_seq2seq</span><span class="params">(encoder_inputs,</span></span></div><div class="line">                                decoder_inputs,</div><div class="line">                                cell,</div><div class="line">                                num_encoder_symbols,</div><div class="line">                                num_decoder_symbols,</div><div class="line">                                embedding_size,</div><div class="line">                                num_heads=<span class="number">1</span>,</div><div class="line">                                output_projection=None,</div><div class="line">                                feed_previous=False,</div><div class="line">                                dtype=None,</div><div class="line">                                scope=None,</div><div class="line">                                initial_state_attention=False)</div></pre></td></tr></table></figure>
<p>与embedding_attention_decoder相对应的seq2seq模型</p>
<h3 id="sequence-loss-by-example"><a href="#sequence-loss-by-example" class="headerlink" title="sequence_loss_by_example"></a>sequence_loss_by_example</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sequence_loss_by_example</span><span class="params">(logits,</span></span></div><div class="line">                             targets,</div><div class="line">                             weights,</div><div class="line">                             average_across_timesteps=True,</div><div class="line">                             softmax_loss_function=None,</div><div class="line">                             name=None):</div><div class="line">  <span class="string">"""Weighted cross-entropy loss for a sequence of logits (per example).</span></div><div class="line">  Args:</div><div class="line">    logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].</div><div class="line">    targets: List of 1D batch-sized int32 Tensors of the same length as logits.</div><div class="line">    weights: List of 1D batch-sized float-Tensors of the same length as logits.</div><div class="line">    average_across_timesteps: If set, divide the returned cost by the total</div><div class="line">      label weight.</div><div class="line">    softmax_loss_function: Function (labels-batch, inputs-batch) -&gt; loss-batch</div><div class="line">      to be used instead of the standard softmax (the default if this is None).</div><div class="line">    name: Optional name for this operation, default: "sequence_loss_by_example".</div><div class="line">  Returns:</div><div class="line">    1D batch-sized float Tensor: The log-perplexity for each sequence.</div><div class="line">  Raises:</div><div class="line">    ValueError: If len(logits) is different from len(targets) or len(weights).</div><div class="line">  """</div><div class="line">  <span class="keyword">if</span> len(targets) != len(logits) <span class="keyword">or</span> len(weights) != len(logits):</div><div class="line">    <span class="keyword">raise</span> ValueError(<span class="string">"Lengths of logits, weights, and targets must be the same "</span></div><div class="line">                     <span class="string">"%d, %d, %d."</span> % (len(logits), len(weights), len(targets)))</div><div class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"sequence_loss_by_example"</span>,</div><div class="line">                      logits + targets + weights):</div><div class="line">    log_perp_list = []</div><div class="line">    <span class="keyword">for</span> logit, target, weight <span class="keyword">in</span> zip(logits, targets, weights):</div><div class="line">      <span class="keyword">if</span> softmax_loss_function <span class="keyword">is</span> <span class="keyword">None</span>:</div><div class="line">        <span class="comment"># TODO(irving,ebrevdo): This reshape is needed because</span></div><div class="line">        <span class="comment"># sequence_loss_by_example is called with scalars sometimes, which</span></div><div class="line">        <span class="comment"># violates our general scalar strictness policy.</span></div><div class="line">        target = array_ops.reshape(target, [<span class="number">-1</span>])</div><div class="line">        crossent = nn_ops.sparse_softmax_cross_entropy_with_logits(</div><div class="line">            labels=target, logits=logit)</div><div class="line">      <span class="keyword">else</span>:</div><div class="line">        crossent = softmax_loss_function(target, logit)</div><div class="line">      log_perp_list.append(crossent * weight)</div><div class="line">    log_perps = math_ops.add_n(log_perp_list)</div><div class="line">    <span class="keyword">if</span> average_across_timesteps:</div><div class="line">      total_size = math_ops.add_n(weights)</div><div class="line">      total_size += <span class="number">1e-12</span>  <span class="comment"># Just to avoid division by 0 for all-0 weights.</span></div><div class="line">      log_perps /= total_size</div><div class="line">  <span class="keyword">return</span> log_perps</div></pre></td></tr></table></figure>
<p>返回值：<br><code>1D batch-sized float Tensor</code>：为每一个序列（一个batch中有batch_size个sequence）计算其log perplexity，也是名称中by_example的含义</p>
<p>输入：<br>(注意：一个batch上的所有数据都被pad成相同长度？因此它们的time_length是一样的？)<br><code>logits</code>：a list依次存储一系列时刻上的输出，每一时刻的输出都是batch_size为单位的，其中的每一个输入对应的输出是<code>整个vocab上的得分</code>，因此是num_decoder_symbols。因此，logits应该是a list of [batch_size, num_decoder_symbols]<br><code>targets</code>：a list表示依次的所有时刻的target，每一时刻又有batch_size个输入，因此对应batch_size个target，因此shape=a list of [batch_size, ]<br><code>weights</code>：每个example，在每一时刻都有对自身当前token的权重。因此shape=a list of [batch_size,]<br><strong>疑问</strong>：weights是做什么用的？为什么要对每个token设置权重？</p>
<p>解读代码：<br>首先会生成一个<code>crossent</code>，shape=[batch_size, ]，再和weights相乘，还是得到[batch_size, ]，表示每个example在当前时刻t位置的得分(batch_size个)，append到log_perp_list中（最终shape是a list of [batch_size, ]）<br>所有的time length循环完毕之后，累加这些time length，得到一个shape=[batch_size,]的变量，叫做log_perps。</p>
<h3 id="sequence-loss"><a href="#sequence-loss" class="headerlink" title="sequence_loss"></a>sequence_loss</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">sequence_loss</span><span class="params">(logits,</span></span></div><div class="line">                  targets,</div><div class="line">                  weights,</div><div class="line">                  average_across_timesteps=True,</div><div class="line">                  average_across_batch=True,</div><div class="line">                  softmax_loss_function=None,</div><div class="line">                  name=None):</div><div class="line">  <span class="string">"""Weighted cross-entropy loss for a sequence of logits, batch-collapsed.</span></div><div class="line">  Args:</div><div class="line">    logits: List of 2D Tensors of shape [batch_size x num_decoder_symbols].</div><div class="line">    targets: List of 1D batch-sized int32 Tensors of the same length as logits.</div><div class="line">    weights: List of 1D batch-sized float-Tensors of the same length as logits.</div><div class="line">    average_across_timesteps: If set, divide the returned cost by the total</div><div class="line">      label weight.</div><div class="line">    average_across_batch: If set, divide the returned cost by the batch size.</div><div class="line">    softmax_loss_function: Function (labels-batch, inputs-batch) -&gt; loss-batch</div><div class="line">      to be used instead of the standard softmax (the default if this is None).</div><div class="line">    name: Optional name for this operation, defaults to "sequence_loss".</div><div class="line">  Returns:</div><div class="line">    A scalar float Tensor: The average log-perplexity per symbol (weighted).</div><div class="line">  Raises:</div><div class="line">    ValueError: If len(logits) is different from len(targets) or len(weights).</div><div class="line">  """</div><div class="line">  <span class="keyword">with</span> ops.name_scope(name, <span class="string">"sequence_loss"</span>, logits + targets + weights):</div><div class="line">    cost = math_ops.reduce_sum(</div><div class="line">        sequence_loss_by_example(</div><div class="line">            logits,</div><div class="line">            targets,</div><div class="line">            weights,</div><div class="line">            average_across_timesteps=average_across_timesteps,</div><div class="line">            softmax_loss_function=softmax_loss_function))</div><div class="line">    <span class="keyword">if</span> average_across_batch:</div><div class="line">      batch_size = array_ops.shape(targets[<span class="number">0</span>])[<span class="number">0</span>]</div><div class="line">      <span class="keyword">return</span> cost / math_ops.cast(batch_size, cost.dtype)</div><div class="line">    <span class="keyword">else</span>:</div><div class="line">      <span class="keyword">return</span> cost</div></pre></td></tr></table></figure>
<p>其实主体还是上面讲的<code>sequence_loss_by_example</code>，只不过对上面的[batch_size,]的结果进行sum，如果默认average_across_batch的话，就sum/batch_size，平均每一个sequence的log perplexity；要是设置了不平均，则返回的是整个batch上的sum of log perplexity</p>
<h3 id="model-with-buckets"><a href="#model-with-buckets" class="headerlink" title="model_with_buckets"></a>model_with_buckets</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">model_with_buckets</span><span class="params">(encoder_inputs,</span></span></div><div class="line">                       decoder_inputs,</div><div class="line">                       targets,</div><div class="line">                       weights,</div><div class="line">                       buckets,</div><div class="line">                       seq2seq,</div><div class="line">                       softmax_loss_function=None,</div><div class="line">                       per_example_loss=False,</div><div class="line">                       name=None):</div><div class="line">  <span class="string">"""Create a sequence-to-sequence model with support for bucketing.</span></div><div class="line">  The seq2seq argument is a function that defines a sequence-to-sequence model,</div><div class="line">  e.g., seq2seq = lambda x, y: basic_rnn_seq2seq(</div><div class="line">      x, y, core_rnn_cell.GRUCell(24))</div><div class="line">  Args:</div><div class="line">    encoder_inputs: A list of Tensors to feed the encoder; first seq2seq input.</div><div class="line">    decoder_inputs: A list of Tensors to feed the decoder; second seq2seq input.</div><div class="line">    targets: A list of 1D batch-sized int32 Tensors (desired output sequence).</div><div class="line">    weights: List of 1D batch-sized float-Tensors to weight the targets.</div><div class="line">    buckets: A list of pairs of (input size, output size) for each bucket.</div><div class="line">    seq2seq: A sequence-to-sequence model function; it takes 2 input that</div><div class="line">      agree with encoder_inputs and decoder_inputs, and returns a pair</div><div class="line">      consisting of outputs and states (as, e.g., basic_rnn_seq2seq).</div><div class="line">    softmax_loss_function: Function (labels-batch, inputs-batch) -&gt; loss-batch</div><div class="line">      to be used instead of the standard softmax (the default if this is None).</div><div class="line">    per_example_loss: Boolean. If set, the returned loss will be a batch-sized</div><div class="line">      tensor of losses for each sequence in the batch. If unset, it will be</div><div class="line">      a scalar with the averaged loss from all examples.</div><div class="line">    name: Optional name for this operation, defaults to "model_with_buckets".</div><div class="line">  Returns:</div><div class="line">    A tuple of the form (outputs, losses), where:</div><div class="line">      outputs: The outputs for each bucket. Its j'th element consists of a list</div><div class="line">        of 2D Tensors. The shape of output tensors can be either</div><div class="line">        [batch_size x output_size] or [batch_size x num_decoder_symbols]</div><div class="line">        depending on the seq2seq model used.</div><div class="line">      losses: List of scalar Tensors, representing losses for each bucket, or,</div><div class="line">        if per_example_loss is set, a list of 1D batch-sized float Tensors.</div><div class="line">  Raises:</div><div class="line">    ValueError: If length of encoder_inputs, targets, or weights is smaller</div><div class="line">      than the largest (last) bucket.</div><div class="line">  """</div></pre></td></tr></table></figure>
<p>参数：<br><code>encoder_inputs</code>：一开始我有个疑问，这里的inputs是ids的形式还是传入input_size的形式，仔细想想实际是这样的。这个inputs具体的shape形式要根据后面seq2seq定义的那个函数决定，一般就只传入两个参数x, y分别对应encoder_inputs和decoder_inputs（另外特定seq2seq需要的参数需要在自定义的这个seq2seq函数内部传入）。这个时候，如果我们使用的是embedding_seq2seq，那么实际的inputs就应该是ids的样子；否则，就是input_size的样子。<br><code>targets</code>：a list因为每一时刻都会有target，并且每一时刻输入的是batch_size个，因此每一时刻的target是[batch_size,]的形式，最终导致targets是a list of [batch_size, ]<br><code>buckets</code>：a list of (input_size, output_size)<br><code>per_example_loss</code>：默认是False，表示losses是[batch_size, ]。比如刚才讲到的sequence_loss_by_example的结果是[batch_size,]，再者sequence_loss的结果是一个scalar。</p>
<p>实现：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">for j, bucket in enumerate(buckets):</div><div class="line">      with variable_scope.variable_scope(</div><div class="line">          variable_scope.get_variable_scope(), reuse=True if j &gt; 0 else None):</div><div class="line">        bucket_outputs, _ = seq2seq(encoder_inputs[:bucket[0]],</div><div class="line">                                    decoder_inputs[:bucket[1]])</div><div class="line">        outputs.append(bucket_outputs)</div></pre></td></tr></table></figure></p>
<p>根据实现可以看到，比如设置了3个buckets=[(2, 4), (5, 7), (8, 10)]，第1个bucket是(2,4)，那么先截取encoder_inputs中每个（batch_size个）sequences的前2个tokens，和同理截取decoder_inputs中前4个tokens（encoder_inputs的第一维度就是time）。<br>然后把截取部分进行seq2seq，得到输出是a list of [batch_size, output_size]（这个list的长度为4，output是按decoder的长度算），然后将这个输出加入到outputs中。<br>最终得到的outputs就是一个bucket_size长度（这里为3）的列表，列表中每个元素是长度不等的list（之所以长度不等是因为每个bucket所定义的max_decoder_length不等，依次增大）</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span> per_example_loss:</div><div class="line">  losses.append(</div><div class="line">      sequence_loss_by_example(</div><div class="line">          outputs[<span class="number">-1</span>],</div><div class="line">          targets[:bucket[<span class="number">1</span>]],</div><div class="line">          weights[:bucket[<span class="number">1</span>]],</div><div class="line">          softmax_loss_function=softmax_loss_function))</div><div class="line"><span class="keyword">else</span>:</div><div class="line">  losses.append(</div><div class="line">      sequence_loss(</div><div class="line">          outputs[<span class="number">-1</span>],</div><div class="line">          targets[:bucket[<span class="number">1</span>]],</div><div class="line">          weights[:bucket[<span class="number">1</span>]],</div><div class="line">          softmax_loss_function=softmax_loss_function))</div></pre></td></tr></table></figure>
<p>计算完当前bucket的outputs后，就应该计算当前bucket的loss。由于当前bucket的output刚刚append，因此outputs[-1]就是当前bucket的output。又因为我们截取了decoder_inputs，因此targets和weights都要截取成相同的长度。这样的话就得到当前bucket的loss，append到losses中。</p>
<p>因此，最后的outputs和losses，我们只要索引bucket的idx，就可以得到该bucket上的output和loss。</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://lan2720.github.io/2017/03/10/tensorflow的legacy-seq2seq/" data-id="cj03yhj2v0000lcfy7mji1ph4" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>

    </footer>
  </div>
  
    
  
</article>

</section>
        
          <aside id="sidebar">
  
    

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签</h3>
    <div class="widget">
      <ul class="tag-list"><li class="tag-list-item"><a class="tag-list-link" href="/tags/tensorflow/">tensorflow</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">标签云</h3>
    <div class="widget tagcloud">
      <a href="/tags/tensorflow/" style="font-size: 10px;">tensorflow</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">归档</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/03/">三月 2017</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">最新文章</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2017/03/10/tensorflow的legacy-seq2seq/">tensorflow的legacy_seq2seq</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2017 Lan2720<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>

  </div>
</body>
</html>